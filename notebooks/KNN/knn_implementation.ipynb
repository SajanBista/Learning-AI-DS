{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f374f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Importing required module\n",
    "\n",
    "class Knnregression():\n",
    "    \"\"\"\n",
    "\n",
    "    K-NN based regression\n",
    "\n",
    "    This is a K-NN regression built using Numpy module that\n",
    "    only supports numerical data as input and euclidean distance\n",
    "    for computing neighbors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k):\n",
    "        '''\n",
    "        Constructs K attribute of K-NN regression\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        k: int\n",
    "          Number of neighbors to take into account in K-NN\n",
    "        '''\n",
    "\n",
    "        self.k= k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        '''\n",
    "        Trains the K-NN model, i.e. storing the training dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train: Numpy.array, shape(n,m)\n",
    "                Training feature matrix\n",
    "        y_train: Numpy.array, shape(n,)\n",
    "                Training target values\n",
    "        '''\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def _calculate_euc_dist_mat(self, X_test):\n",
    "        '''\n",
    "        Computes the euclidean distance matrix between two feature vectors\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_test: Numpy.array, shape(z,m)\n",
    "            New feature matrix, this feature vector and stored one's euclidean\n",
    "            distance is computed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        euc_mat: Numpy.array, shape(n,z)\n",
    "            Euclidean distance matrix, here element (1,1) is euclidean distance\n",
    "            between stored data's 1st sample and new data's 1st sample, (1,2)\n",
    "            between stored data's 1st sample and new data's 2nd sample and so on.\n",
    "        '''\n",
    "        a = np.sum(self.X_train**2, axis=1).reshape(-1,1) # Reshaping for proper euclidean matrix.\n",
    "        b_T = np.sum(X_test**2, axis=1)\n",
    "        W = -2 * np.dot(self.X_train,X_test.T)\n",
    "        euc_mat = np.sqrt(a + b_T + W + 1e-10) # Adding small value to avoid warning.\n",
    "\n",
    "        return euc_mat\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        '''\n",
    "        Predicts the target labels of provided data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_test: Numpy.array, shape(z,m)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array(self.predictions): Numpy,array, shape(z,)\n",
    "                Predictions of the target labels\n",
    "        '''\n",
    "\n",
    "        self.predictions = []\n",
    "\n",
    "        dist_mat = self._calculate_euc_dist_mat(X_test)\n",
    "\n",
    "        for i in range(X_test.shape[0]):\n",
    "            distance = dist_mat[:,i] # Taking ith column of distance matrix\n",
    "            near_neigh_index = np.argsort(distance)[:self.k]\n",
    "            near_neigh_labels = self.y_train.iloc[near_neigh_index]\n",
    "\n",
    "\n",
    "            self.predictions.append(np.mean(near_neigh_labels)) # Aggregation\n",
    "\n",
    "        return np.array(self.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca68f8b2",
   "metadata": {},
   "source": [
    "# KNN( k- Nearest Neighbour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc261f",
   "metadata": {},
   "source": [
    "### Import dataset and feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d93af853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3cac33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Crime_rate_per_capita', 'Residential_land_zone_pct',\n",
      "       'Non_retail_business_acres_pct', 'Next_to_Charles_River',\n",
      "       'Nitric_Oxide_conc', 'Avg_rooms_per_dwelling',\n",
      "       'Pct_houses_built_before_1940', 'Weighted_dist_to_employment',\n",
      "       'Highway_access_index', 'Property_tax_rate_per_10000',\n",
      "       'Pupil_teacher_ratio', 'Black_residents_index', 'Low_income_pct',\n",
      "       'Median_home_value_1000s'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n",
    "df = pd.read_csv(url)\n",
    "# New descriptive column names\n",
    "new_column_names = {\n",
    "    'crim': 'Crime_rate_per_capita',\n",
    "    'zn': 'Residential_land_zone_pct',\n",
    "    'indus': 'Non_retail_business_acres_pct',\n",
    "    'chas': 'Next_to_Charles_River',\n",
    "    'nox': 'Nitric_Oxide_conc',\n",
    "    'rm': 'Avg_rooms_per_dwelling',\n",
    "    'age': 'Pct_houses_built_before_1940',\n",
    "    'dis': 'Weighted_dist_to_employment',\n",
    "    'rad': 'Highway_access_index',\n",
    "    'tax': 'Property_tax_rate_per_10000',\n",
    "    'ptratio': 'Pupil_teacher_ratio',\n",
    "    'b': 'Black_residents_index',\n",
    "    'lstat': 'Low_income_pct',\n",
    "    'medv': 'Median_home_value_1000s'\n",
    "}\n",
    "\n",
    "# Rename columns\n",
    "df = df.rename(columns=new_column_names)\n",
    "\n",
    "# Check new columns\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "afa68314",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =df.drop('Median_home_value_1000s', axis =1)\n",
    "y = df['Median_home_value_1000s']\n",
    "\n",
    "X_scaled = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5b7e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2078e4ca",
   "metadata": {},
   "source": [
    "### Fitting the KNN regression and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36435e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg = Knnregression(k=4)\n",
    "knn_reg.fit(X_train, y_train)\n",
    "\n",
    "knn_y_train_pred = knn_reg.predict(X_train)\n",
    "knn_y_test_pred = knn_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb1399",
   "metadata": {},
   "source": [
    "### Performance Comparision with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f052bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN, Training MSE: 11.91\n",
      "KNN, Test MSE: 19.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "knn_train_error = mean_squared_error(y_train, knn_y_train_pred)\n",
    "knn_test_error = mean_squared_error(y_test, knn_y_test_pred)\n",
    "\n",
    "print(f'KNN, Training MSE: {knn_train_error:.2f}')\n",
    "print(f'KNN, Test MSE: { knn_test_error:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd546ca",
   "metadata": {},
   "source": [
    "Now lets fit the linear regression and compute MSE on training  and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88b9c345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression, Training MSE: 21.641412753226312\n",
      "Linear Regression, Test MSE: 24.291119474973545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "lin_y_train_pred = lin_reg.predict(X_train)\n",
    "lin_y_test_pred = lin_reg.predict(X_test)\n",
    "\n",
    "lin_train_error = mean_squared_error(y_train, lin_y_train_pred)\n",
    "\n",
    "lin_test_error = mean_squared_error(y_test, lin_y_test_pred)\n",
    "\n",
    "print(f'Linear Regression, Training MSE: {lin_train_error}')\n",
    "\n",
    "print(f'Linear Regression, Test MSE: {lin_test_error}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
